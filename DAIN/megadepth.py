from functools import reduce

import torch
import torch.nn as nn


class LambdaBase(nn.Sequential):
    def __init__(self, fn, *args):
        super(LambdaBase, self).__init__(*args)
        self.lambda_func = fn

    def forward_prepare(self, input):
        output = []
        for module in self._modules.values():
            output.append(module(input))
        return output if output else input

class Lambda(LambdaBase):
    def forward(self, input):
        return self.lambda_func(self.forward_prepare(input))

class LambdaMap(LambdaBase):
    def forward(self, input):
        return list(map(self.lambda_func,self.forward_prepare(input)))

class LambdaReduce(LambdaBase):
    def forward(self, input):
        return reduce(self.lambda_func,self.forward_prepare(input))

network = nn.Sequential(nn.Conv2d(3,128,(7, 7),(1, 1),(3, 3)),
									nn.BatchNorm2d(128),
									nn.ReLU(),
									nn.Sequential( # Sequential,
										LambdaMap(lambda x: x, # ConcatTable,
											nn.Sequential( # Sequential,
												nn.MaxPool2d((2, 2),(2, 2)),
												LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
													nn.Sequential( # Sequential,
														nn.Conv2d(128,32,(1, 1)),
														nn.BatchNorm2d(32,1e-05,0.1,False),
														nn.ReLU(),
													),
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,32,(3, 3),(1, 1),(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,32,(5, 5),(1, 1),(2, 2)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,32,(7, 7),(1, 1),(3, 3)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
										),
										LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,32,(3, 3),(1, 1),(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,32,(5, 5),(1, 1),(2, 2)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(128,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,32,(7, 7),(1, 1),(3, 3)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
											),
										),
										nn.Sequential( # Sequential,
											LambdaMap(lambda x: x, # ConcatTable,
												nn.Sequential( # Sequential,
													nn.MaxPool2d((2, 2),(2, 2)),
													LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
														nn.Sequential( # Sequential,
															nn.Conv2d(128,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(128,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,32,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(128,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,32,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(128,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,32,(7, 7),(1, 1),(3, 3)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
														),
													),
													LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
														nn.Sequential( # Sequential,
															nn.Conv2d(128,64,(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(128,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(128,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
														nn.Conv2d(128,32,(1, 1)),
														nn.BatchNorm2d(32,1e-05,0.1,False),
														nn.ReLU(),
														nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
														nn.BatchNorm2d(64,1e-05,0.1,False),
														nn.ReLU(),
													),
												),
												nn.Sequential( # Sequential,
													LambdaMap(lambda x: x, # ConcatTable,
														nn.Sequential( # Sequential,
															LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
															),
															LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(64,64,(3, 3),(1, 1),(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(64,64,(7, 7),(1, 1),(3, 3)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(64,64,(11, 11),(1, 1),(5, 5)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
															),
														),
														nn.Sequential( # Sequential,
															nn.AvgPool2d((2, 2),(2, 2)),
															LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
													),
													LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
														nn.Sequential( # Sequential,
															nn.Conv2d(256,64,(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
														nn.Conv2d(256,32,(1, 1)),
														nn.BatchNorm2d(32,1e-05,0.1,False),
														nn.ReLU(),
														nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
														nn.BatchNorm2d(64,1e-05,0.1,False),
														nn.ReLU(),
													),
												),
												nn.Sequential( # Sequential,
													LambdaMap(lambda x: x, # ConcatTable,
														nn.Sequential( # Sequential,
															LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
															),
															LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
																	nn.BatchNorm2d(32,1e-05,0.1,False),
																	nn.ReLU(),
																	nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
															),
														),
														nn.Sequential( # Sequential,
															nn.AvgPool2d((2, 2),(2, 2)),
															LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,64,(1, 1)),
																	nn.BatchNorm2d(64,1e-05,0.1,False),
																	nn.ReLU(),
																),
																nn.Sequential( # Sequential,
																	nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
													),
													LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
														nn.Sequential( # Sequential,
															nn.Conv2d(256,64,(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
													),
													LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
														nn.Sequential( # Sequential,
															nn.Conv2d(256,64,(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
														nn.Sequential( # Sequential,
															nn.Conv2d(256,32,(1, 1)),
															nn.BatchNorm2d(32,1e-05,0.1,False),
															nn.ReLU(),
															nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
															nn.BatchNorm2d(64,1e-05,0.1,False),
															nn.ReLU(),
														),
													),
													nn.UpsamplingNearest2d(scale_factor=2),
												),
											),
											LambdaReduce(lambda x,y: x+y), # CAddTable,
										),
										LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
											nn.Sequential( # Sequential,
												nn.Conv2d(256,64,(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(256,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(256,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(256,32,(1, 1)),
												nn.BatchNorm2d(32,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
										),
										LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
											nn.Sequential( # Sequential,
												nn.Conv2d(256,64,(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(256,64,(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(64,64,(3, 3),(1, 1),(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(256,64,(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(64,64,(7, 7),(1, 1),(3, 3)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
											nn.Sequential( # Sequential,
												nn.Conv2d(256,64,(1, 1)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
												nn.Conv2d(64,64,(11, 11),(1, 1),(5, 5)),
												nn.BatchNorm2d(64,1e-05,0.1,False),
												nn.ReLU(),
											),
										),
										nn.UpsamplingNearest2d(scale_factor=2),
									),
								),
								LambdaReduce(lambda x,y: x+y), # CAddTable,
							),
							LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
								nn.Sequential( # Sequential,
									nn.Conv2d(256,64,(1, 1)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,64,(3, 3),(1, 1),(1, 1)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,64,(5, 5),(1, 1),(2, 2)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,64,(7, 7),(1, 1),(3, 3)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
								),
							),
							LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,32,(3, 3),(1, 1),(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,32,(5, 5),(1, 1),(2, 2)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(256,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,32,(7, 7),(1, 1),(3, 3)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
							),
							nn.UpsamplingNearest2d(scale_factor=2),
						),
						nn.Sequential( # Sequential,
							LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
								nn.Sequential( # Sequential,
									nn.Conv2d(128,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(128,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,32,(3, 3),(1, 1),(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(128,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,32,(5, 5),(1, 1),(2, 2)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(128,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(32,32,(7, 7),(1, 1),(3, 3)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
							),
							LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
								nn.Sequential( # Sequential,
									nn.Conv2d(128,32,(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(128,64,(1, 1)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(64,32,(3, 3),(1, 1),(1, 1)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(128,64,(1, 1)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(64,32,(7, 7),(1, 1),(3, 3)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
								nn.Sequential( # Sequential,
									nn.Conv2d(128,64,(1, 1)),
									nn.BatchNorm2d(64,1e-05,0.1,False),
									nn.ReLU(),
									nn.Conv2d(64,32,(11, 11),(1, 1),(5, 5)),
									nn.BatchNorm2d(32,1e-05,0.1,False),
									nn.ReLU(),
								),
							),
						),
					),
					LambdaReduce(lambda x,y: x+y), # CAddTable,
				),
				LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
					nn.Sequential( # Sequential,
						nn.Conv2d(128,32,(1, 1)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,64,(1, 1)),
						nn.BatchNorm2d(64,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(64,32,(3, 3),(1, 1),(1, 1)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,64,(1, 1)),
						nn.BatchNorm2d(64,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(64,32,(5, 5),(1, 1),(2, 2)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,64,(1, 1)),
						nn.BatchNorm2d(64,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(64,32,(7, 7),(1, 1),(3, 3)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
					),
				),
				LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
					nn.Sequential( # Sequential,
						nn.Conv2d(128,16,(1, 1)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,32,(1, 1)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(32,16,(3, 3),(1, 1),(1, 1)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,32,(1, 1)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(32,16,(7, 7),(1, 1),(3, 3)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,32,(1, 1)),
						nn.BatchNorm2d(32,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(32,16,(11, 11),(1, 1),(5, 5)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
				),
				nn.UpsamplingNearest2d(scale_factor=2),
			),
			nn.Sequential( # Sequential,
				LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
					nn.Sequential( # Sequential,
						nn.Conv2d(128,16,(1, 1)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,64,(1, 1)),
						nn.BatchNorm2d(64,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(64,16,(3, 3),(1, 1),(1, 1)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,64,(1, 1)),
						nn.BatchNorm2d(64,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(64,16,(7, 7),(1, 1),(3, 3)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
					nn.Sequential( # Sequential,
						nn.Conv2d(128,64,(1, 1)),
						nn.BatchNorm2d(64,1e-05,0.1,False),
						nn.ReLU(),
						nn.Conv2d(64,16,(11, 11),(1, 1),(5, 5)),
						nn.BatchNorm2d(16,1e-05,0.1,False),
						nn.ReLU(),
					),
				),
			),
		),
		LambdaReduce(lambda x,y: x+y), # CAddTable,
	),
	nn.Conv2d(64,1,(3, 3),(1, 1),(1, 1)),
)

class HourGlass():

    def __init__(self, pretrained=None):

        model = network
        if pretrained is None:
            self.netG = model
        else:
            pretrained_dict = torch.load(pretrained)

            model_dict = model.state_dict()
            pretrained_dict = {k[7:]: v for k, v in pretrained_dict.items()}  # and not k[:10]== 'rectifyNet'}
            model_dict.update(pretrained_dict)
            model.load_state_dict(model_dict)
            pretrained_dict = None
            self.netG = model



    def batch_classify(self, z_A_arr, z_B_arr, ground_truth ):
        threashold = 1.1
        depth_ratio = torch.div(z_A_arr, z_B_arr)

        depth_ratio = depth_ratio.cpu()

        estimated_labels = torch.zeros(depth_ratio.size(0))

        estimated_labels[depth_ratio > (threashold)] = 1
        estimated_labels[depth_ratio < (1/threashold)] = -1

        diff = estimated_labels - ground_truth
        diff[diff != 0] = 1

        # error 
        inequal_error_count = diff[ground_truth != 0]
        inequal_error_count =  torch.sum(inequal_error_count)

        error_count = torch.sum(diff) #diff[diff !=0]

        equal_error_count = error_count - inequal_error_count


        # total 
        total_count = depth_ratio.size(0)
        ground_truth[ground_truth !=0 ] = 1

        inequal_count_total = torch.sum(ground_truth)
        equal_total_count = total_count - inequal_count_total


        error_list = [equal_error_count, inequal_error_count, error_count]
        count_list = [equal_total_count, inequal_count_total, total_count]

        return error_list, count_list 


    def computeSDR(self, prediction_d, targets):
        #  for each image 
        total_error = [0,0,0]
        total_samples = [0,0,0]

        for i in range(0, prediction_d.size(0)):

            if targets['has_SfM_feature'][i] == False:
                continue
            
            x_A_arr = targets["sdr_xA"][i].squeeze(0)
            x_B_arr = targets["sdr_xB"][i].squeeze(0)
            y_A_arr = targets["sdr_yA"][i].squeeze(0)
            y_B_arr = targets["sdr_yB"][i].squeeze(0)

            predict_depth = torch.exp(prediction_d[i,:,:])
            predict_depth = predict_depth.squeeze(0)
            ground_truth = targets["sdr_gt"][i]


            z_A_arr = torch.gather( torch.index_select(predict_depth, 1 ,x_A_arr.cuda()) , 0, y_A_arr.view(1, -1).cuda())# predict_depth:index(2, x_A_arr):gather(1, y_A_arr:view(1, -1))
            z_B_arr = torch.gather( torch.index_select(predict_depth, 1 ,x_B_arr.cuda()) , 0, y_B_arr.view(1, -1).cuda())

            z_A_arr = z_A_arr.squeeze(0)
            z_B_arr = z_B_arr.squeeze(0)

            error_list, count_list  = self.batch_classify(z_A_arr, z_B_arr,ground_truth)

            for j in range(0,3):
                total_error[j] += error_list[j]
                total_samples[j] += count_list[j]

        return  total_error, total_samples


    def evaluate_SDR(self, input_, targets):
        input_images = input_.cuda()
        prediction_d = self.netG.forward(input_images) 

        total_error, total_samples = self.computeSDR(prediction_d.data, targets)

        return total_error, total_samples

    def rmse_Loss(self, log_prediction_d, mask, log_gt):
        N = torch.sum(mask)
        log_d_diff = log_prediction_d - log_gt
        log_d_diff = torch.mul(log_d_diff, mask)
        s1 = torch.sum( torch.pow(log_d_diff,2) )/N 

        s2 = torch.pow(torch.sum(log_d_diff),2)/(N*N)  
        data_loss = s1 - s2

        data_loss = torch.sqrt(data_loss)

        return data_loss

    def evaluate_RMSE(self, input_images, prediction_d, targets):
        count = 0            
        total_loss = torch.cuda.FloatTensor(1)
        total_loss[0] = 0
        mask_0 = targets['mask_0'].cuda().detach_()
        d_gt_0 = torch.log(targets['gt_0'].cuda(), requires_grad = False)

        for i in range(0, mask_0.size(0)):
 
            total_loss +=  self.rmse_Loss(prediction_d[i,:,:], mask_0[i,:,:], d_gt_0[i,:,:])
            count += 1

        return total_loss.data[0], count


    def evaluate_sc_inv(self, input_, targets):
        input_images = input_.cuda()
        prediction_d = self.netG.forward(input_images) 
        rmse_loss , count= self.evaluate_RMSE(input_images, prediction_d, targets)

        return rmse_loss, count


    def switch_to_train(self):
        self.netG.train()

    def switch_to_eval(self):
        self.netG.eval()


if __name__ == "__main__":
	h = HourGlass()
	# from torch.hub import load_state_dict_from_url
	# state_dict = load_state_dict_from_url("http://vllab1.ucmerced.edu/~wenbobao/DAIN/best_generalization_net_G.pth")
	# HourGlass.load_state_dict(state_dict)
	# print(HourGlass)

